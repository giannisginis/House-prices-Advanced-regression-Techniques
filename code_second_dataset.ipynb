{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# machine learning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .csv files\n",
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Id', u'MSSubClass', u'MSZoning', u'LotFrontage', u'LotArea',\n",
       "       u'Street', u'Alley', u'LotShape', u'LandContour', u'Utilities',\n",
       "       u'LotConfig', u'LandSlope', u'Neighborhood', u'Condition1',\n",
       "       u'Condition2', u'BldgType', u'HouseStyle', u'OverallQual',\n",
       "       u'OverallCond', u'YearBuilt', u'YearRemodAdd', u'RoofStyle',\n",
       "       u'RoofMatl', u'Exterior1st', u'Exterior2nd', u'MasVnrType',\n",
       "       u'MasVnrArea', u'ExterQual', u'ExterCond', u'Foundation', u'BsmtQual',\n",
       "       u'BsmtCond', u'BsmtExposure', u'BsmtFinType1', u'BsmtFinSF1',\n",
       "       u'BsmtFinType2', u'BsmtFinSF2', u'BsmtUnfSF', u'TotalBsmtSF',\n",
       "       u'Heating', u'HeatingQC', u'CentralAir', u'Electrical', u'1stFlrSF',\n",
       "       u'2ndFlrSF', u'LowQualFinSF', u'GrLivArea', u'BsmtFullBath',\n",
       "       u'BsmtHalfBath', u'FullBath', u'HalfBath', u'BedroomAbvGr',\n",
       "       u'KitchenAbvGr', u'KitchenQual', u'TotRmsAbvGrd', u'Functional',\n",
       "       u'Fireplaces', u'FireplaceQu', u'GarageType', u'GarageYrBlt',\n",
       "       u'GarageFinish', u'GarageCars', u'GarageArea', u'GarageQual',\n",
       "       u'GarageCond', u'PavedDrive', u'WoodDeckSF', u'OpenPorchSF',\n",
       "       u'EnclosedPorch', u'3SsnPorch', u'ScreenPorch', u'PoolArea', u'PoolQC',\n",
       "       u'Fence', u'MiscFeature', u'MiscVal', u'MoSold', u'YrSold', u'SaleType',\n",
       "       u'SaleCondition', u'SalePrice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>259</td>\n",
       "      <td>17.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total    Percent\n",
       "PoolQC         1453  99.520548\n",
       "MiscFeature    1406  96.301370\n",
       "Alley          1369  93.767123\n",
       "Fence          1179  80.753425\n",
       "FireplaceQu     690  47.260274\n",
       "LotFrontage     259  17.739726\n",
       "GarageCond       81   5.547945\n",
       "GarageType       81   5.547945\n",
       "GarageYrBlt      81   5.547945\n",
       "GarageFinish     81   5.547945\n",
       "GarageQual       81   5.547945\n",
       "BsmtExposure     38   2.602740\n",
       "BsmtFinType2     38   2.602740\n",
       "BsmtFinType1     37   2.534247\n",
       "BsmtCond         37   2.534247\n",
       "BsmtQual         37   2.534247\n",
       "MasVnrArea        8   0.547945\n",
       "MasVnrType        8   0.547945\n",
       "Electrical        1   0.068493\n",
       "Utilities         0   0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing data\n",
    "total = data.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100*(data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a few houses with more than 4000 sq ft living area that are\n",
    "# outliers, so we drop them from the dataset\n",
    "data=data[data[\"GrLivArea\"] < 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new=data.drop([\"Id\",\"PoolQC\",\"MiscVal\",\"MiscFeature\",\"Fence\",\"FireplaceQu\",\"LotFrontage\",\n",
    "                 \"Alley\",\"GarageYrBlt\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create simple imputer and use it to fill nan values \n",
    "from sklearn.preprocessing import Imputer\n",
    "median_imputer = Imputer(strategy='median')\n",
    "data_new['MasVnrArea'] = median_imputer.fit_transform(data_new['MasVnrArea'].reshape(-1, 1))\n",
    "#missing values of numerical columns\n",
    "total = data_new.isnull().sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical features mapping\n",
    "obj_df = data_new.select_dtypes(include=['object']).copy()\n",
    "for i in obj_df:\n",
    "    obj_df[i] = obj_df[i].astype('category')\n",
    "\n",
    "for i in obj_df:\n",
    "    obj_df[i] = obj_df[i].cat.codes\n",
    "#export numerical features\n",
    "numerical_features = data_new.select_dtypes(include=[\"float\",\"int\",\"bool\"]).copy()\n",
    "#concat to new dataframe\n",
    "dataset=pd.concat([numerical_features,obj_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data size:\n",
      "((1456, 72), (1456,))\n",
      "\n",
      "Training data size:\n",
      "((1092, 71), (1092,))\n",
      "\n",
      "Test data size:\n",
      "((364, 71), (364,))\n"
     ]
    }
   ],
   "source": [
    "# Splitting up a training and test (validation) set\n",
    "X = dataset.drop(\"SalePrice\", axis=1)\n",
    "y= dataset[\"SalePrice\"]\n",
    "frac_test = 0.25\n",
    "#frac_test_2 = 0.5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = frac_test, random_state=5)\n",
    "#x_train2, x_test, y_train2, y_test = train_test_split(x_2, y_2, test_size = frac_test_2, random_state=23)\n",
    "\n",
    "print('Full data size:')\n",
    "print(dataset.shape, data['SalePrice'].shape)\n",
    "print('\\nTraining data size:')\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('\\nTest data size:')\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()  # define scaler\n",
    "scaler.fit(X_train)  # fit scaler ONLY on the training data\n",
    "\n",
    "# print('mean: {}\\nstd:  {}'.format(scaler.mean_ , scaler.scale_))\n",
    "\n",
    "# transform on both sets:\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #numpy to pd\n",
    "# X_train_scaled=pd.DataFrame(X_train_scaled)\n",
    "# X_train_scaled.columns=X.columns\n",
    "# # X_train_scaled.shape\n",
    "# X_test_scaled=pd.DataFrame(X_test_scaled)\n",
    "# X_test_scaled.columns=X.columns\n",
    "# # X_test_scaled.shape\n",
    "# y_train=pd.DataFrame(y_train)\n",
    "# y_train.columns=y_train.columns\n",
    "# y_test=pd.DataFrame(y_test)\n",
    "# y_test.columns=y_test.columns\n",
    "# # #export to csv normalized dataset\n",
    "# X_train_scaled.to_csv('X_train_scaled.csv', sep=';',index=False)\n",
    "# X_test_scaled.to_csv('X_test_scaled.csv', sep=';',index=False)\n",
    "# y_train.to_csv('y_train.csv', sep=';',index=False)\n",
    "# y_test.to_csv('y_test.csv', sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate correlation of features with Sales price\n",
    "corr_concat = pd.concat([X_train,y_train], axis=1)\n",
    "corrmat = corr_concat.corr()\n",
    "corr_list = corrmat['SalePrice'].sort_values(axis=0,ascending=False).iloc[1:]\n",
    "# features with correlation >0.45 and <(-0.45)\n",
    "feat=corr_list[((corr_list.values >0.45)|(corr_list.values < (-0.4))) ].index.tolist()\n",
    "#remove columns of the remaining ones with low correlation among them\n",
    "remove_list = ['1stFlrSF','GarageArea','TotRmsAbvGrd','YearRemodAdd','OverallQual']\n",
    "feat=[ x for x in feat if x not in remove_list ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full data size:\n",
      "((1456, 10), (1456,))\n",
      "\n",
      "Training data size:\n",
      "((1092, 10), (1092,))\n",
      "\n",
      "Test data size:\n",
      "((364, 10), (364,))\n"
     ]
    }
   ],
   "source": [
    "# Splitting up again a training and test (validation) set\n",
    "X = dataset[feat]\n",
    "y= dataset[\"SalePrice\"]\n",
    "frac_test = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = frac_test, random_state=5)\n",
    "\n",
    "print('Full data size:')\n",
    "print(dataset[feat].shape, data['SalePrice'].shape)\n",
    "print('\\nTraining data size:')\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('\\nTest data size:')\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_pred, y_test) :\n",
    "   assert len(y_test) == len(y_pred)\n",
    "   return np.sqrt(np.mean((np.log(1+y_pred) - np.log(1+y_test))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LR:', 0.17088235037245464)\n",
      "('NN:', 0.22265437368701754)\n",
      "('KNN:', 0.2138175503380746)\n"
     ]
    }
   ],
   "source": [
    "# Training different models.\n",
    "\n",
    "#LR\n",
    "reg =linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "pred_LR = reg.predict(X_test)\n",
    "print(\"LR:\", rmsle(pred_LR,y_test))\n",
    "\n",
    "# # Neural Net\n",
    "nn = MLPRegressor(hidden_layer_sizes=(10,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "nn.fit(X_train, y_train)\n",
    "pred_nn = nn.predict(X_test)\n",
    "print(\"NN:\", rmsle(pred_nn,y_test))\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "knn.fit(X_train,y_train)\n",
    "predictions_KNN = knn.predict(X_test)\n",
    "print(\"KNN:\", rmsle(predictions_KNN,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Forest:', 0.1565453755921989)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_jobs=1, random_state=0,n_estimators=500, max_features=0.01, max_depth=11)\n",
    "rf.fit(X_train,y_train)\n",
    "predictions_RF = rf.predict(X_test)\n",
    "print(\"Random Forest:\", rmsle(y_test,predictions_RF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Decision Tree:', 0.2239369096407867)\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeRegressor(random_state=21)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "predictions_DT = decision_tree.predict(X_test)\n",
    "print(\"Decision Tree:\", rmsle(predictions_DT,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVR:', 0.36929026623622496)\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "clf = SVR(C=1.0, epsilon=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_SVM = clf.predict(X_test)\n",
    "print(\"SVR:\", rmsle(y_test,pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "#from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, LassoCV,LassoLarsCV, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from scipy.stats import skew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_extra_trees_regression(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    etr = ExtraTreesRegressor(n_jobs=1, random_state=77)\n",
    "    param_grid = {'max_features': [0.01,1,5]}\n",
    "    model = GridSearchCV(estimator=etr, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Extra trees regression...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "    #print('Best CV Score:')\n",
    "    #print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra trees regression...\n",
      "Best Params:\n",
      "{'max_features': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17131055833716277"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_extra_trees_regression(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning tree-specific parameters\n",
    "def model_extra_trees_regression(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    etr = ExtraTreesRegressor(n_jobs=1, random_state=77,max_features=0.01)\n",
    "    param_grid = {'n_estimators': range(20,350,30)}\n",
    "    model = GridSearchCV(estimator=etr, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Extra trees regression...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "    #print('Best CV Score:')\n",
    "    #print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra trees regression...\n",
      "Best Params:\n",
      "{'n_estimators': 230}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16048093178048187"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_extra_trees_regression(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Tuning parameters\n",
    "def model_extra_trees_regression(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    etr = ExtraTreesRegressor(n_jobs=1, random_state=77,max_features=5,n_estimators=230)\n",
    "    param_grid = {'min_samples_leaf':range(1,20,5), 'max_features':range(5,10,2)}\n",
    "    model = GridSearchCV(estimator=etr, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Extra trees regression...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "    #print('Best CV Score:')\n",
    "    #print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra trees regression...\n",
      "Best Params:\n",
      "{'max_features': 5, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16201853727635424"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_extra_trees_regression(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "min_samples_split = 0.01  #This should be ~0.5-1% of total values. \n",
    "min_samples_leaf = 50 #Can be selected based on intuition. This is just used for preventing overfitting \n",
    "max_depth = 3\n",
    "max_features = 'sqrt' #Its a general thumb-rule to start with square root.\n",
    "def random_forest(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_grid = {'n_estimators': range(20,501,10)}\n",
    "    model = GridSearchCV(estimator = RandomForestRegressor(min_samples_split=min_samples_split, \n",
    "                                                              min_samples_leaf=min_samples_leaf,\n",
    "                                                              max_depth=max_depth,\n",
    "                                                              max_features=max_features,\n",
    "                                                              random_state=5), \n",
    "                                                              param_grid = param_grid, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Random Forest...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest...\n",
      "Best Params:\n",
      "{'n_estimators': 270}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19561021054762717"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning tree-specific parameters\n",
    "def random_forest(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_grid = {'max_depth': range(1,16,2), 'min_samples_split': np.arange(0.001, 0.011, 0.001)}\n",
    "    model = GridSearchCV(estimator = RandomForestRegressor(min_samples_split=min_samples_split, \n",
    "                                                              min_samples_leaf=min_samples_leaf,\n",
    "                                                              max_depth=max_depth,\n",
    "                                                              max_features=max_features,\n",
    "                                                              random_state=5,n_estimators=270), \n",
    "                                                              param_grid = param_grid, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Random Forest...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest...\n",
      "Best Params:\n",
      "{'min_samples_split': 0.001, 'max_depth': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1816754848880955"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third Tuning\n",
    "def random_forest(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_grid = {'min_samples_leaf':range(10,101,10), 'max_features':range(1,10,2)}\n",
    "    model = GridSearchCV(estimator = RandomForestRegressor(min_samples_split=0.001, \n",
    "                                                              min_samples_leaf=min_samples_leaf,\n",
    "                                                              max_depth=7,\n",
    "                                                              max_features=max_features,\n",
    "                                                              random_state=5,n_estimators=270), \n",
    "                                                              param_grid = param_grid, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Random Forest...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest...\n",
      "Best Params:\n",
      "{'max_features': 7, 'min_samples_leaf': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15693177119790136"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting\n",
    "min_samples_split = 0.01  #This should be ~0.5-1% of total values. \n",
    "min_samples_leaf = 50 #Can be selected based on intuition. This is just used for preventing overfitting \n",
    "max_depth = 3\n",
    "max_features = 'sqrt' #Its a general thumb-rule to start with square root.\n",
    "subsample = 0.8 #This is a commonly used used start value\n",
    "learning_rate=0.3\n",
    "\n",
    "def gboosting(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_test1 = {'n_estimators': range(20,501,10)}\n",
    "    model = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=learning_rate, min_samples_split=min_samples_split, \n",
    "                                                              min_samples_leaf=min_samples_leaf,max_depth=max_depth,\n",
    "                                                              max_features=max_features,\n",
    "                                                              subsample=subsample,random_state=10), \n",
    "                                                              param_grid = param_test1, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Gradient Boosting...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting...\n",
      "Best Params:\n",
      "{'n_estimators': 120}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15456727681485227"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboosting(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gboosting(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_test2 = {'max_depth': range(1,16,2), 'min_samples_split': np.arange(0.001, 0.011, 0.001)}\n",
    "    model = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=learning_rate, min_samples_split=min_samples_split, \n",
    "                                                              min_samples_leaf=min_samples_leaf,max_depth=max_depth,\n",
    "                                                              max_features=max_features,\n",
    "                                                              subsample=subsample,random_state=10,n_estimators=120), \n",
    "                                                              param_grid = param_test2, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Gradient Boosting...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting...\n",
      "Best Params:\n",
      "{'min_samples_split': 0.001, 'max_depth': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15456727681485227"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboosting(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gboosting(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_test3 = {'min_samples_leaf':range(10,101,10), 'max_features':range(1,10,1)}\n",
    "    model = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=learning_rate, min_samples_split=0.001, \n",
    "                                                              min_samples_leaf=min_samples_leaf,max_depth=3,\n",
    "                                                              max_features=max_features,\n",
    "                                                              subsample=subsample,random_state=10,n_estimators=180), \n",
    "                                                              param_grid = param_test3, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Gradient Boosting...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting...\n",
      "Best Params:\n",
      "{'max_features': 4, 'min_samples_leaf': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16062335166682012"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gboosting(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "def ridge(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_test3 = {'alpha': 10**np.random.uniform(-1,1, size=100)}\n",
    "    model = GridSearchCV(estimator = linear_model.Ridge(),param_grid = param_test3, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('ridge...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge...\n",
      "Best Params:\n",
      "{'alpha': 9.765349084760425}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1723350550200072"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def lasso(Xtrain,Xtest,ytrain,y_test):\n",
    "    \n",
    "    X_train = Xtrain\n",
    "    y_train = ytrain\n",
    "    \n",
    "    param_test3 = {'alpha': 10**np.random.uniform(-6,1,size=100)}\n",
    "    model = GridSearchCV(estimator = Lasso(),param_grid = param_test3, n_jobs=4,iid=False,cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('lasso...')\n",
    "    print('Best Params:')\n",
    "    print(model.best_params_)\n",
    "#     print('Best CV Score:')\n",
    "#     print(-model.best_score_)\n",
    "\n",
    "    y_pred = model.predict(Xtest)\n",
    "    return  rmsle(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso...\n",
      "Best Params:\n",
      "{'alpha': 5.905370906977447}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17282906835493972"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python_2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
